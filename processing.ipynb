{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\romer\\anaconda3\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from pytesseract) (9.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.4)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\romer\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pytesseract\n",
    "!python -m pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\romer\\anaconda3\\lib\\site-packages (1.23.12)\n",
      "Requirement already satisfied: pillow in c:\\users\\romer\\anaconda3\\lib\\site-packages (9.0.1)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.9 in c:\\users\\romer\\anaconda3\\lib\\site-packages (from pymupdf) (1.23.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "    pip install pymupdf pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' # replace this path with the path to your tesseract installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesseract_path = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = r'TOCs\\NAAL TOCs\\2007\\2007_Baym_The_Norton_anthology_of_American.pdf'\n",
    "output_folder = r'TOCs\\NAAL TOCs\\2007\\processed'\n",
    "include_pngs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "processing.pdf_to_data(pdf_path, output_folder, tesseract_path, include_pngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_data(pdf_path, output_folder, include_pngs= False):\n",
    "    '''Chop a given PDF into individual pages, then convert each PDF into an image (saved to the pngs folder). Convert OCR data about each page into a .csv.\n",
    "        This function requires that you have a folder in the same level as your pdf for outputs, and then two folders within that folder titled 'pngs' and 'tsv_data'.\n",
    "        For example:\n",
    "            your pdf\n",
    "            output folder\n",
    "                pngs ** Only necessary if you want to see the processed pages-- set include_pngs to True'''\n",
    "    \n",
    "    open_pdf = fitz.open(pdf_path)\n",
    "\n",
    "    sum_string = ''\n",
    "    tsv_total = pd.DataFrame()\n",
    "    for page_num in range(open_pdf.page_count): # iterate through individual pages\n",
    "        page = open_pdf[page_num]\n",
    "\n",
    "        img = page.get_pixmap()\n",
    "        \n",
    "\n",
    "        # make the image\n",
    "        pil_img = Image.frombytes(\"RGB\", [img.width, img.height], img.samples) # convert to PIL Image\n",
    "        # improve resolution\n",
    "        scale_factor = 3 # try changing this to improve resolution\n",
    "        new_size = img.width * scale_factor, img.height * scale_factor\n",
    "        resize = pil_img.resize(new_size, Image.LANCZOS)\n",
    "        \n",
    "\n",
    "        # process image into tsv and clean some values\n",
    "        png_to_data = pytesseract.image_to_data(resize, config = r'--psm 6') \n",
    "        data_to_tsv = StringIO(png_to_data)\n",
    "        data_read = pd.read_csv(data_to_tsv, sep='\\t', quoting=csv.QUOTE_NONE)\n",
    "        tsv_clean = data_read[['line_num', 'word_num', 'left', 'top', 'text', 'conf']]\n",
    "        tsv_total = pd.concat([tsv_total, tsv_clean])\n",
    "\n",
    "        img_to_string = pytesseract.image_to_string(resize, config = r'--psm 6', lang = 'en')\n",
    "        sum_string += img_to_string\n",
    "        \n",
    "        if include_pngs:\n",
    "            output_png_path = Path(f\"{output_folder}/pngs/page_{page_num + 1}.png\")\n",
    "            resize.save(output_png_path)\n",
    "\n",
    "    output_tsv_total = Path(f\"{output_folder}/location.csv\")\n",
    "    tsv_total.to_csv(output_tsv_total, sep= ',', index=False)\n",
    "    #print(sum_string)\n",
    "    output_str_path = Path(f\"{output_folder}/str_data.txt\")\n",
    "    with open(output_str_path, 'w') as file:\n",
    "        file.write(sum_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa9 in position 269: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Read and parse the file\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[0;32m     19\u001b[0m         line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()  \u001b[38;5;66;03m# Remove whitespace\u001b[39;00m\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;66;03m# Check if the line contains only an author name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\romer\\anaconda3\\lib\\codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa9 in position 269: invalid start byte"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# Paths to input and output files\n",
    "input_path = r'TOCs\\NAFAM 3\\processed_v1\\str_data.txt' # Update with your actual file path\n",
    "output_path = 'output_data.csv'\n",
    "\n",
    "# Regular expressions for identifying titles and page numbers\n",
    "title_page_pattern = re.compile(r'^(.*?)\\s+(\\d+)$')  # Matches \"Title    PageNumber\"\n",
    "author_pattern = re.compile(r'^[A-Za-z]{2,}(?:\\s[A-Za-z]{2,}){0,4}$')  # Matches lines with only author names\n",
    "\n",
    "# Initialize list to store parsed entries and a variable to keep track of the last seen author\n",
    "parsed_data = []\n",
    "last_author = \"Unknown\"\n",
    "\n",
    "# Read and parse the file\n",
    "with open(input_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()  # Remove whitespace\n",
    "\n",
    "        # Check if the line contains only an author name\n",
    "        author_match = author_pattern.match(line)\n",
    "        if author_match:\n",
    "            last_author = author_match.group(0).strip()\n",
    "            continue  # Move to the next line\n",
    "\n",
    "        # Check for \"Title    PageNumber\" format\n",
    "        title_page_match = title_page_pattern.match(line)\n",
    "        if title_page_match:\n",
    "            work = title_page_match.group(1).strip()\n",
    "            page_number = title_page_match.group(2)\n",
    "            parsed_data.append([work, last_author, page_number])\n",
    "            continue\n",
    "\n",
    "# Write parsed data to a CSV file\n",
    "with open(output_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Work\", \"Author\", \"Page Number\"])  # Write headers\n",
    "    writer.writerows(parsed_data)  # Write data rows\n",
    "\n",
    "print(f'Data successfully written to {output_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
